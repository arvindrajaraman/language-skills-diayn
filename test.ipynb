{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any, Callable, Sequence\n",
    "from jax import random, numpy as jnp\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to use CUDA because of the following issues with CUDA components:\n",
      "Outdated cuDNN installation found.\n",
      "Version JAX was built against: 8906\n",
      "Minimum supported: 8900\n",
      "Installed version: 8500\n",
      "The local installation version must be no lower than 8900. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(5, 8)\n"
     ]
    }
   ],
   "source": [
    "done = jnp.array([True, False,  True, False, True], dtype=bool)\n",
    "obs = jnp.array([[ 0.5162862 ,  0.2074894 ,  0.7240187 , -1.0787021 ,  0.04069785,\n",
    "                 -0.06364991,  1.        ,  0.        ],\n",
    "                [ 0.11500321,  1.1899251 ,  0.50547856, -0.419965  , -0.2609647 ,\n",
    "                 -0.33009827,  0.        ,  0.        ],\n",
    "                [-0.63004315, -0.23130883, -0.3797977 , -0.47536182,  2.8034565 ,\n",
    "                  1.9403803 ,  0.        ,  0.        ],\n",
    "                [-0.153934  ,  1.1053196 , -0.3867789 , -0.58739966,  0.3082726 ,\n",
    "                  0.06706445,  0.        ,  0.        ],\n",
    "                [-0.0033843 ,  1.4856167 ,  0.04007225,  0.00840264, -0.11051258,\n",
    "                 -0.24021249,  0.        ,  0.        ]], dtype=jnp.float32)\n",
    "\n",
    "print(done.shape)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4]\n",
      "[ 0.5162862  -0.63004315 -0.0033843 ]\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "def classify_goal(x):\n",
    "    result = jnp.zeros_like(x, dtype=jnp.int32)\n",
    "    result = result.at[x < -0.33].set(0)\n",
    "    result = result.at[(x >= -0.33) & (x < 0.33)].set(1)\n",
    "    result = result.at[x >= 0.33].set(2)\n",
    "\n",
    "    return result\n",
    "\n",
    "done_idx = jnp.argwhere(done).reshape(-1)\n",
    "goal_idx = classify_goal(obs[done_idx, 0])\n",
    "\n",
    "print(done_idx)\n",
    "print(obs[done_idx, 0])\n",
    "print(goal_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to use CUDA because of the following issues with CUDA components:\n",
      "Outdated cuDNN installation found.\n",
      "Version JAX was built against: 8906\n",
      "Minimum supported: 8900\n",
      "Installed version: 8500\n",
      "The local installation version must be no lower than 8900. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_view (7, 9)\n",
      "map_view_one_hot (7, 9, 17)\n",
      "mob_map (7, 9, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/arvindrajaraman/anaconda3/envs/diayn/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_view (7, 9)\n",
      "map_view_one_hot (7, 9, 17)\n",
      "mob_map (7, 9, 4)\n"
     ]
    }
   ],
   "source": [
    "from craftax_classic.envs.craftax_symbolic_env import CraftaxClassicSymbolicEnv\n",
    "from environment_base.wrappers import AutoResetEnvWrapper, BatchEnvWrapper\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, _rng = jax.random.split(rng)\n",
    "rngs = jax.random.split(_rng, 3)\n",
    "\n",
    "# Create environment\n",
    "env = AutoResetEnvWrapper(CraftaxClassicSymbolicEnv())\n",
    "env_params = env.default_params\n",
    "\n",
    "# Get an initial state and observation\n",
    "obs, state = env.reset(rngs[0], env_params)\n",
    "\n",
    "# Pick random action\n",
    "action = env.action_space(env_params).sample(rngs[1])\n",
    "\n",
    "# Step environment\n",
    "obs, state, reward, done, info = env.step(rngs[2], state, action, env_params)\n",
    "\n",
    "# print(all_map.flatten().shape)\n",
    "# print(inventory.shape)\n",
    "# print(intrinsics.shape)\n",
    "# print(direction.shape)\n",
    "# print(jnp.array([state.light_level, state.is_sleeping]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1345,)\n"
     ]
    }
   ],
   "source": [
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load iris dataset from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features and labels\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert X and y into jnp arrays\n",
    "X = jnp.array(X)\n",
    "y = jnp.array(y)\n",
    "\n",
    "# Convert y into one hot\n",
    "y = jnp.eye(3)[y]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    hidden1_size: int\n",
    "    hidden2_size: int\n",
    "    hidden3_size: int\n",
    "    output_size: int\n",
    "    \n",
    "    dropout_rate: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=False):\n",
    "        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not train)\n",
    "        x = nn.Dense(features=self.hidden1_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not train)\n",
    "        x = nn.Dense(features=self.hidden2_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not train)\n",
    "        x = nn.Dense(features=self.hidden3_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.output_size)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "    # attributes\n",
      "    hidden1_size = 64\n",
      "    hidden2_size = 64\n",
      "    hidden3_size = 16\n",
      "    output_size = 3\n",
      "    dropout_rate = 0.2\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "input_shape = (768,)\n",
    "\n",
    "model = MLP(hidden1_size=64, hidden2_size=64, hidden3_size=16, output_size=3, dropout_rate=0.2)\n",
    "params = model.init(key, jnp.ones(input_shape, jnp.float32))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1345)\n",
      "(10, 7, 9, 21)\n",
      "(10, 22)\n"
     ]
    }
   ],
   "source": [
    "dummy_obs = jnp.ones((10, 1345))\n",
    "print(dummy_obs.shape)\n",
    "\n",
    "maps, metadata = jnp.split(dummy_obs, [7 * 9 * 21], axis=1)\n",
    "maps = maps.reshape((-1, 7, 9, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetCraftax(nn.Module):\n",
    "    action_size: 17\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        maps, metadata = jnp.split(x, [7 * 9 * 21], axis=1)\n",
    "        maps = maps.reshape((-1, 7, 9, 21))\n",
    "        \n",
    "        maps = nn.Conv(features=32, kernel_size=(3, 3), padding='SAME')(maps)\n",
    "        maps = nn.relu(maps)\n",
    "        maps = nn.max_pool(maps, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        maps = nn.Conv(features=64, kernel_size=(3, 3), padding='SAME')(maps)\n",
    "        maps = nn.relu(maps)\n",
    "        maps = nn.max_pool(maps, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        maps_features = maps.reshape((maps.shape[0], -1))\n",
    "\n",
    "        fc_inputs = jnp.concatenate((maps_features, metadata), axis=-1)\n",
    "        y = nn.Dense(128)(fc_inputs)\n",
    "        y = nn.relu(y)\n",
    "        y = nn.Dense(64)(fc_inputs)\n",
    "        y = nn.relu(y)\n",
    "        y = nn.Dense(self.action_size)(y)\n",
    "        y = nn.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "model = QNetCraftax(action_size=17)\n",
    "params = model.init(key, dummy_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diayn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
